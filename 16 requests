

import requests
import json
from ruamel.yaml import YAML 


'''
params：请求参数，字典类型，常用于发送 GET 请求时使用。
data:一般用于提交表单数据元素
timeout：超时时间 ，整数类型。
headers：设置请求头。
auth：指定登陆时的账号和密码，元祖类型
verify:请求网站时是否需要验证，布尔类型
proxies:设置代理
cookies：cookies 值
allow_redirects：布尔值，默认为Ture，重定向开关
stream：布尔值，默认为True，为True时会先下载响应头，当Reponse调用content方法时才下载响应体
cert：传入客户端的SSL证书，为字符串时应是 SSL 客户端证书文件的路径(.pem格式，文件路径包含密钥和证书)，如果是元组，就应该是一个(‘cert’, ‘key’) 二元值对。
'''

#GET请求
HTTP默认的请求方法就是GET
    * 没有请求体
    * 数据必须在1K之内！
    * GET请求数据会暴露在浏览器的地址栏中

GET请求常用的操作：
    1. 在浏览器的地址栏中直接给出URL，那么就一定是GET请求
    2. 点击页面上的超链接也一定是GET请求
    3. 提交表单时，表单默认使用GET请求，但可以设置为POST

#POST请求
    1. 数据不会出现在地址栏中
    2. 数据的大小没有上限
    3. 有请求体
    4. 请求体中如果存在中文，会使用URL编码！

#！！！requests.post()用法与requests.get()完全一致，特殊的是requests.post()有一个data参数，用来存放请求体数据


# #### 响应：
# #allow_redirects=False#设置这个属性为False则是不允许重定向，反之可以重定向 
# response = requests.get("http://www.baidu.com",allow_redirects=False)
# print(response.status_code)
# #打印请求网址的headers所有信息,返回字典类型
# print(response.headers)
# 返回发送到服务器的头信息                             
# print(response.requests.headers)                        
# #打印请求网址的cookies信息
# print(response.cookies)
# print(respone.cookies.get_dict())
# print(respone.cookies.items())
# #打印请求网址的地址
# print(response.url)
# #打印请求的历史记录（以列表的形式显示）
# print(response.history)


# ####服务器相应内容
# # 1、读取服务器响应的内容
# response.text
# # Requests文本编码,能够使用 r.encoding 属性来改变它
# response.encoding
# # 2、二进制响应内容,以字节的方式访问请求响应体，对于非文本请求，可以用于下载图片以及视频资源
# response.content
# # 3、JSON 响应内容，内置的 JSON 解码器，助你处理 JSON 数据
# response.json()
# # 获取来自服务器的原始套接字响应
# response.raw


# ####其它操作
# #把cookie对象转化为字典
# requests.utils.dict_from_cookiejar
# #把字典转化为cookie对象
# requests.utils.cookiejar_from_dict
# #url解码
# requests.utils.unquote()
# #url编码
# requests.utils.quote()


#==============================================================================#


# 模拟浏览器

# import requests
 
# url = 'https://www.zhihu.com/'
# headers = {
#     'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36'
# }
# response = requests.get(url,headers=headers)
# print(response.text)


#-------------------------------------------------------------------------------


# 如果想查询http://httpbin.org/get页面的具体参数，需要在url里面加上，例如我想看有没有Host=httpbin.org这条数据，url形式应该是http://httpbin.org/get?Host=httpbin.org

# import requests
 
# url = 'http://httpbin.org/get'
# data = {
#     'name':'zhangsan',
#     'age':'25'
# }
# response = requests.get(url,params=data)
# print(response.url)
# print(response.text)

#-------------------------------------------------------------------------------

#通过post把数据提交到url地址，等同于一字典的形式提交form表单里面的数据

# import requests
 
# url = 'http://httpbin.org/post'
# data = {
#     'name':'jack',
#     'age':'23'
#     }
# response = requests.post(url,data=data)
# print(response.text)


# import requests
# import json
 
# r = requests.post('https://api.github.com/some/endpoint', data=json.dumps({'some': 'data'}))
# print(r.json())

#-------------------------------------------------------------------------------

# 获取cookie
# cookie的一个作用就是可以用于模拟登陆，做会话维持，那么我们可以利用 cookies参数拿到：
 
# import requests
 
# response = requests.get("http://www.baidu.com/")
# # 返回CookieJar对象:

# print(response.cookies)
# for key,value in response.cookies.items():
#     print(key,'==',value)

# cookiejar = response.cookies
# # 将CookieJar转为字典：
# cookiedict = requests.utils.dict_from_cookiejar(cookiejar)
 
# print cookiejar
# print cookiedict

# print(respone.cookies.get_dict())
# print(respone.cookies.items())

# 会话维持:
# SESSION这个对象代表一次用户会话：从客户端浏览器连接服务器开始，到客户端浏览器与服务器断开。会话能让我们在跨请求时候保持某些参数，比如在同一个 Session 实例发出的所有请求之间保持 cookie 。

# import requests
 
# # 1. 创建session对象，可以保存Cookie值
# ssion = requests.session()
 
# # 2. 处理 headers
# headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"}
 
# # 3. 需要登录的用户名和密码
# data = {"email":"mr_mao_hacker@163.com", "password":"alarmchime"}  
 
# # 4. 发送附带用户名和密码的请求，并获取登录后的Cookie值，保存在ssion里
# ssion.post("http://www.renren.com/PLogin.do", data = data)
 
# # 5. ssion包含用户登录后的Cookie值，可以直接访问那些登录后才可以访问的页面
# response = ssion.get("http://www.renren.com/410043129/profile")
 
# # 6. 打印响应内容
# print response.text


# s = requests.Session()
# s.auth = ('auth','passwd')
# s.headers = {'key':'value'}
# r = s.get('url')
# r1 = s.get('url1')

# 会话对象让你能够跨请求保持某些参数，最方便的是在同一个Session实例发出的所有请求之间保持cookies，且这些都是自动处理的，甚是方便。
# 下面就来一个真正的实例，如下是快盘签到脚本：

# import requests
# headers = {'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
#            'Accept-Encoding': 'gzip, deflate, compress',
#            'Accept-Language': 'en-us;q=0.5,en;q=0.3',
#            'Cache-Control': 'max-age=0',
#            'Connection': 'keep-alive',
#            'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:22.0) Gecko/20100101 Firefox/22.0'}
 
# s = requests.Session()
# s.headers.update(headers)
# # s.auth = ('superuser', '123')
# s.get('https://www.kuaipan.cn/account_login.htm')
 
# _URL = 'http://www.kuaipan.cn/index.php'
# s.post(_URL, params={'ac':'account', 'op':'login'},
#        data={'username':'****@foxmail.com', 'userpwd':'********', 'isajax':'yes'})
# r = s.get(_URL, params={'ac':'zone', 'op':'taskdetail'})
# print(r.json())
# s.get(_URL, params={'ac':'common', 'op':'usersign'})

#-------------------------------------------------------------------------------


# 验证设置：

# 如果是Web客户端验证，需要添加 auth = (账户名, 密码)

# import requests
# from requests.auth import HTTPBasicAuth

# #方法一
# r = requests.get('http://120.27.34.24:9001', auth=HTTPBasicAuth('user', '123'))

# #方法二
# r = requests.get('http://120.27.34.24:9001', auth=('user', '123'))


#-------------------------------------------------------------------------------


# 正向代理与反向代理:

# 设置普通代理:

# import requests
 
# proxies = {
#   "http": "http://127.0.0.1:9743",
#   "https": "https://127.0.0.1:9743",
# }
# response = requests.get("https://www.taobao.com", proxies=proxies)
# print(response.status_code)

# 也可以通过本地环境变量 HTTP_PROXY 和 HTTPS_PROXY 来配置代理：
# export HTTP_PROXY="http://12.34.56.79:9527"
# export HTTPS_PROXY="https://12.34.56.79:9527"

# 私密代理：
 
# import requests
# # 如果代理需要使用HTTP Basic Auth，可以使用下面这种格式：
# proxy = { "http": "mr_mao_hacker:sffqry9r@61.158.163.130:16816" }
# response = requests.get("http://www.baidu.com", proxies = proxy)
# print response.text


# # 设置socks代理
# # 安装socks模块 pip3 install 'requests[socks]'

# import requests
# proxies = {
#     'http': 'socks5://127.0.0.1:9742',
#     'https': 'socks5://127.0.0.1:9742'
# }
# response = requests.get("https://www.taobao.com", proxies=proxies)
# print(response.status_code)


#-------------------------------------------------------------------------------

# 文件上传：

# import requests
# url = "http://httpbin.org/post"
# files= {"files":open("test.jpg","rb")}
# response = requests.post(url,files=files)
# print(response.text)

# request更加方便的是，可以把字符串当作文件进行上传：

# import requests
# url = 'http://127.0.0.1:8080/upload'
# files = {'file': ('test.txt', b'Hello Requests.')}     #必需显式的设置文件名
# r = requests.post(url, files=files)
# print(r.text)

#-------------------------------------------------------------------------------

# 关闭SSL证书验证：

# import requests
# # 关闭验证，但是仍然会报出证书警告
# import requests
# response = requests.get('https://www.12306.cn',verify=False)
# print(response.status_code)

# 消除验证证书的警报：

# from requests.packages import urllib3
# import requests
# urllib3.disable_warnings()
# response = requests.get('https://www.12306.cn',verify=False)
# print(response.status_code)

# 手动设置证书：

# import requests
# response = requests.get('https://www.12306.cn', cert=('/path/server.crt', '/path/key'))
# print(response.status_code)


#-------------------------------------------------------------------------------


# # 超时设置:
# # 通过timeout参数可以设置超时的时间

# import requests
# from requests.exceptions import ReadTimeout
 
# try:
#     # 设置必须在500ms内收到响应，不然或抛出ReadTimeout异常
#     response = requests.get("http://httpbin.org/get", timeout=0.5)
#     print(response.status_code)
# except ReadTimeout:
#     print('Timeout')



#-------------------------------------------------------------------------------

# 状态异常处理:

# import requests

# URL = 'http://ip.taobao.com/service/getIpInfo.php'  # 淘宝IP地址库API
# try:
#     r = requests.get(URL, params={'ip': '8.8.8.8'}, timeout=1)
#     r.raise_for_status()  # 如果响应状态码不是 200，就主动抛出异常
# except requests.RequestException as e:
#     print(e)
# else:
#     result = r.json()
#     print(type(result), result, sep='\n')


